{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644269fc",
   "metadata": {},
   "source": [
    "# Train Q-learning agent on Taxi-v3\n",
    "\n",
    "This notebook reuses `backend/taxi/rl_agent.py` to train a simple Q-learning agent, then reports basic metrics and shows a sample successful trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce7c49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on Colab, install dependencies\n",
    "import sys, os\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    !pip -q install -U gymnasium==0.26.2 numpy\n",
    "\n",
    "# Ensure backend is importable\n",
    "repo_root = os.getcwd()\n",
    "backend_path = os.path.join(repo_root, 'backend')\n",
    "if backend_path not in sys.path:\n",
    "    sys.path.append(backend_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from taxi.rl_agent import QLearningAgent, solve_taxi_v3_and_collect_data\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the agent with configurable episodes\n",
    "EPISODES = 2000\n",
    "ALPHA = 0.1\n",
    "GAMMA = 0.99\n",
    "EPSILON = 1.0\n",
    "EPS_DECAY = 0.995\n",
    "EPS_MIN = 0.01\n",
    "\n",
    "env = gym.make('Taxi-v3')\n",
    "agent = QLearningAgent(env, alpha=ALPHA, gamma=GAMMA, epsilon=EPSILON, epsilon_decay=EPS_DECAY, epsilon_min=EPS_MIN)\n",
    "successful_episodes = agent.train(episodes=EPISODES)\n",
    "env.close()\n",
    "len(successful_episodes), successful_episodes[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c250ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute basic metrics over training\n",
    "total_success = len(successful_episodes)\n",
    "avg_success_reward = float(np.mean([ep['total_reward'] for ep in successful_episodes])) if successful_episodes else 0.0\n",
    "print('Successful episodes:', total_success)\n",
    "print('Average reward among successes:', avg_success_reward)\n",
    "# Save to JSON for downstream analysis or explanation generation\n",
    "with open('rl_successful_episodes.json', 'w') as f:\n",
    "    json.dump(successful_episodes, f, indent=2)\n",
    "print('Saved to rl_successful_episodes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561e284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: generate natural-language explanations using backend.llm.explanation_generator\n",
    "# Requires OPENAI_API_KEY to be set if using OpenAI.\n",
    "from llm.explanation_generator import generate_explanation_for_rl_steps\n",
    "try:\n",
    "    explanations = generate_explanation_for_rl_steps(successful_episodes[:3])\n",
    "    print('Generated', len(explanations), 'explanations. Example:')\n",
    "    explanations[0] if explanations else {}\n",
    "except Exception as e:\n",
    "    print('Explanation generation skipped due to error:', e)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
