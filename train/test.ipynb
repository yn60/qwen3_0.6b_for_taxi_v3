{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# é‡å¯åè¿è¡Œè¿™ä¸ªå®Œæ•´éªŒè¯\n",
        "import os\n",
        "import json\n",
        "import sys\n",
        "\n",
        "print(\"ğŸ¯ é‡å¯åå®Œæ•´éªŒè¯ä¸‰ä¸ªæ ¸å¿ƒæ–‡ä»¶\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 1. è®¾ç½®é¡¹ç›®è·¯å¾„\n",
        "project_root = '/content/qwen3_0.6b_for_taxi_v3'\n",
        "sys.path.append(project_root)\n",
        "print(f\"ğŸ”§ é¡¹ç›®è·¯å¾„: {project_root}\")\n",
        "\n",
        "# 2. æ£€æŸ¥æ ¸å¿ƒæ–‡ä»¶å¯¼å…¥\n",
        "print(\"\\nğŸ“ æ£€æŸ¥æ ¸å¿ƒæ–‡ä»¶å¯¼å…¥:\")\n",
        "try:\n",
        "    from backend.taxi.rl_agent import solve_taxi_v3_and_collect_data\n",
        "    print(\"  âœ… backend.taxi.rl_agent å¯¼å…¥æˆåŠŸ\")\n",
        "\n",
        "    from run_pipeline import run_data_collection_and_explanation_pipeline\n",
        "    print(\"  âœ… run_pipeline å¯¼å…¥æˆåŠŸ\")\n",
        "\n",
        "    from backend.llm.explanation_generator import generate_explanation_for_rl_steps\n",
        "    print(\"  âœ… backend.llm.explanation_generator å¯¼å…¥æˆåŠŸ\")\n",
        "\n",
        "    print(\"âœ… æ‰€æœ‰æ ¸å¿ƒæ–‡ä»¶å¯¼å…¥æˆåŠŸ\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ å¯¼å…¥å¤±è´¥: {e}\")\n",
        "    exit()\n",
        "\n",
        "# 3. è¿è¡Œæ•°æ®æ”¶é›†æµ‹è¯•\n",
        "print(\"\\nğŸš€ è¿è¡Œæ•°æ®æ”¶é›†æµ‹è¯•:\")\n",
        "try:\n",
        "    # ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬æµ‹è¯•æ•°æ®æ”¶é›†\n",
        "    def test_data_collection():\n",
        "        successful_episodes = solve_taxi_v3_and_collect_data()\n",
        "        print(f\"  âœ… æ•°æ®æ”¶é›†æˆåŠŸ: {len(successful_episodes)} episodes\")\n",
        "\n",
        "        # ä¿å­˜æ•°æ®\n",
        "        output_dir = os.path.join(project_root, 'finetuning_data')\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        output_file = os.path.join(output_dir, 'test_training_data.json')\n",
        "\n",
        "        with open(output_file, 'w') as f:\n",
        "            json.dump(successful_episodes, f, indent=2)\n",
        "\n",
        "        print(f\"  âœ… è®­ç»ƒæ•°æ®ä¿å­˜åˆ°: {output_file}\")\n",
        "        return successful_episodes, output_file\n",
        "\n",
        "    episodes, file_path = test_data_collection()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ æ•°æ®æ”¶é›†å¤±è´¥: {e}\")\n",
        "    exit()\n",
        "\n",
        "# 4. éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶\n",
        "print(\"\\nğŸ“ éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶:\")\n",
        "if os.path.exists(file_path):\n",
        "    size_kb = os.path.getsize(file_path) / 1024\n",
        "    print(f\"  âœ… è®­ç»ƒæ•°æ®æ–‡ä»¶å­˜åœ¨: {file_path} ({size_kb:.1f} KB)\")\n",
        "\n",
        "    # éªŒè¯æ–‡ä»¶å†…å®¹\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        print(f\"  âœ… æ–‡ä»¶å†…å®¹æœ‰æ•ˆ: {len(data)} episodes\")\n",
        "\n",
        "        if data:\n",
        "            first_episode = data[0]\n",
        "            print(f\"  ğŸ“Š æ ·æœ¬æ•°æ®:\")\n",
        "            print(f\"    - Episode: {first_episode['episode']}\")\n",
        "            print(f\"    - æ€»å¥–åŠ±: {first_episode['total_reward']}\")\n",
        "            print(f\"    - æ­¥æ•°: {len(first_episode['steps'])}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ æ–‡ä»¶å†…å®¹éªŒè¯å¤±è´¥: {e}\")\n",
        "else:\n",
        "    print(f\"  âŒ è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ğŸ‰ æœ€ç»ˆéªŒè¯ç»“æœ:\")\n",
        "print(\"âœ… ä¸‰ä¸ªæ ¸å¿ƒæ–‡ä»¶å¯ä»¥æ­£å¸¸å¯¼å…¥\")\n",
        "print(\"âœ… RLæ•°æ®æ”¶é›†åŠŸèƒ½æ­£å¸¸å·¥ä½œ\")\n",
        "print(\"âœ… è®­ç»ƒæ•°æ®æ–‡ä»¶æˆåŠŸç”Ÿæˆ\")\n",
        "print(\"âœ… è¾¾åˆ°è¦æ±‚ï¼šå¯ä»¥æ”¶é›†è®­ç»ƒæ•°æ®\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N54KXpcX-X1",
        "outputId": "4d29316e-c525-4c48-eed2-6e08605012ea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¯ é‡å¯åå®Œæ•´éªŒè¯ä¸‰ä¸ªæ ¸å¿ƒæ–‡ä»¶\n",
            "==================================================\n",
            "ğŸ”§ é¡¹ç›®è·¯å¾„: /content/qwen3_0.6b_for_taxi_v3\n",
            "\n",
            "ğŸ“ æ£€æŸ¥æ ¸å¿ƒæ–‡ä»¶å¯¼å…¥:\n",
            "  âœ… backend.taxi.rl_agent å¯¼å…¥æˆåŠŸ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  âœ… run_pipeline å¯¼å…¥æˆåŠŸ\n",
            "  âœ… backend.llm.explanation_generator å¯¼å…¥æˆåŠŸ\n",
            "âœ… æ‰€æœ‰æ ¸å¿ƒæ–‡ä»¶å¯¼å…¥æˆåŠŸ\n",
            "\n",
            "ğŸš€ è¿è¡Œæ•°æ®æ”¶é›†æµ‹è¯•:\n",
            "  âœ… æ•°æ®æ”¶é›†æˆåŠŸ: 1 episodes\n",
            "  âœ… è®­ç»ƒæ•°æ®ä¿å­˜åˆ°: /content/qwen3_0.6b_for_taxi_v3/finetuning_data/test_training_data.json\n",
            "\n",
            "ğŸ“ éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶:\n",
            "  âœ… è®­ç»ƒæ•°æ®æ–‡ä»¶å­˜åœ¨: /content/qwen3_0.6b_for_taxi_v3/finetuning_data/test_training_data.json (20.0 KB)\n",
            "  âœ… æ–‡ä»¶å†…å®¹æœ‰æ•ˆ: 1 episodes\n",
            "  ğŸ“Š æ ·æœ¬æ•°æ®:\n",
            "    - Episode: 6\n",
            "    - æ€»å¥–åŠ±: -374.0\n",
            "    - æ­¥æ•°: 89\n",
            "\n",
            "==================================================\n",
            "ğŸ‰ æœ€ç»ˆéªŒè¯ç»“æœ:\n",
            "âœ… ä¸‰ä¸ªæ ¸å¿ƒæ–‡ä»¶å¯ä»¥æ­£å¸¸å¯¼å…¥\n",
            "âœ… RLæ•°æ®æ”¶é›†åŠŸèƒ½æ­£å¸¸å·¥ä½œ\n",
            "âœ… è®­ç»ƒæ•°æ®æ–‡ä»¶æˆåŠŸç”Ÿæˆ\n",
            "âœ… è¾¾åˆ°è¦æ±‚ï¼šå¯ä»¥æ”¶é›†è®­ç»ƒæ•°æ®\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fbiiIyezYKNH"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}